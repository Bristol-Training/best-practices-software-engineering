{"title":"Input data for tests","markdown":{"yaml":{"title":"Input data for tests"},"headingText":"A different example","containsRefs":false,"markdown":"\n\n\n\nAs we saw in the last section, when using parametrisation it's often useful to split your test function into two logical parts:\n\n- The data to be tested\n- The code to do the test\n\nThis is because we had a situation where we had one test function and multiple examples to test. The opposite situation also happens where we have multiple test functions, all of which want the same input data.\n\nThe name that pytest uses for \"data which are provided to test functions\" is *fixture* since it *fixes* a set of data against which to test.\n\nWe'll start with the example of the `add_arrays` function to explain the syntax but soon we'll need to use an example which demonstates the benefits more.\n\nTo make things clearer, we'll trim down the test file back to the basics. Just one test for `add_arrays`:\n\n\n```python\n\n\"\"\"\nThis module contains functions for manipulating and combining Python lists.\n\"\"\"\n\ndef add_arrays(x, y):\n    \"\"\"\n    This function adds together each element of the two passed lists.\n\n    Args:\n        x (list): The first list to add\n        y (list): The second list to add\n\n    Returns:\n        list: the pairwise sums of ``x`` and ``y``.\n\n    Examples:\n        >>> add_arrays([1, 4, 5], [4, 3, 5])\n        [5, 7, 10]\n    \"\"\"\n\n    if len(x) != len(y):\n        raise ValueError(\"Both arrays must have the same length.\")\n\n    z = []\n    for x_, y_ in zip(x, y):\n        z.append(x_ + y_)\n\n    return z\n```\n\n\n```python\n\nfrom arrays import add_arrays\n\ndef test_add_arrays():\n    a = [1, 2, 3]\n    b = [4, 5, 6]\n    expect = [5, 7, 9]\n    \n    output = add_arrays(a, b)\n    \n    assert output == expect\n```\n\nTo create our fixture we define a function which is decorated with the `pytest.fixture` decorator. Apart from that, all the function needs to do is return the data we want to provide to our tests, in this case, the two input lists:\n\n```python\nimport pytest\n\n@pytest.fixture\ndef pair_of_lists():\n    return [1, 2, 3], [4, 5, 6]\n```\n\n\nTo make the test functions make use of the fixture, we use the name of the fixture (`pair_of_lists`) as a parameter of the test function, similar to how we did with parametrisation:\n\n```python\ndef test_add_arrays(pair_of_lists):\n    ...\n```\n\nThe data are now available inside the function using that name and we can use it however we wish:\n\n```python\ndef test_add_arrays(pair_of_lists):\n    a, b = pair_of_lists\n    ...\n```\n\nThis isn't how functions and arguments usually work in Python. pytest is doing something magic here and is matching up the names of things which it knows are fixtures (due to the decorator) with the names of parameters to test functions, automatically running the fixture and passing in the data.\n\nNote that `pair_of_lists` here is not a test function. It does not contain any `assert`s and will not  explicitly appear in the `pytest` output.\n\nPutting it all together, we end up with:\n\n\n```python\n\nimport pytest\n\nfrom arrays import add_arrays\n\n@pytest.fixture\ndef pair_of_lists():\n    return [1, 2, 3], [4, 5, 6]\n\ndef test_add_arrays(pair_of_lists):\n    a, b = pair_of_lists\n    expect = [5, 7, 9]\n    \n    output = add_arrays(a, b)\n    \n    assert output == expect\n```\n\nWhen we run the test suite, pytest will automatically run the `pair_of_lists` function for any test that has it as an input and pass in the result.\n\n\n```python\nCOLUMNS=60 pytest -v test_arrays.py\n```\n\n    \u001b[1m=================== test session starts ====================\u001b[0m\n    platform linux -- Python 3.8.12, pytest-6.2.5, py-1.10.0, pluggy-1.0.0 -- /usr/bin/python3.8\n    cachedir: .pytest_cache\n    rootdir: /home/matt/projects/courses/software_engineering_best_practices\n    plugins: anyio-3.3.4\n    collected 1 item                                           \u001b[0m\n    \n    test_arrays.py::test_add_arrays \u001b[32mPASSED\u001b[0m\u001b[32m               [100%]\u001b[0m\n    \n    \u001b[32m==================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m =====================\u001b[0m\n\n\n\nIt might be hard to see the benefit of fixtures with this rather contrived example in which there aren't repeated uses of the same input data. So lets take a look at a more sensible one where using a fixture makes sense.\n\nMake a new file called `books.py` which contains the following:\n\n\n```python\n\ndef word_count(text, word=''):\n    \"\"\"\n    Count the number of occurences of ``word`` in a string.\n    If ``word`` is not set, count all words.\n    \n    Args:\n        text (str): the text corpus to search through\n        word (str): the word to count instances of\n\n    Returns:\n        int: the count of ``word`` in ``text``\n    \"\"\"\n    if word:\n        count = 0\n        for text_word in text.split():\n            if text_word == word:\n                count += 1\n        return count\n    else:\n        return len(text.split())\n```\n\n\n\nTo test this function we want a corpus of text to test it on. For the purposes of this example and to simulate a complex data input, we will download the contents of a particularly long novel from Project Gutenberg. Our test function uses [`urllib.request`](https://docs.python.org/3/library/urllib.request.html) to download the text, converts it to a string and passes that to the `word_count` function.\n\nAt first we will simply check that the word \"hat\" appears 33 times in the book:\n\n\n```python\n\nimport urllib.request\n\nfrom books import word_count\n\ndef test_word_counts():\n    url = \"https://www.gutenberg.org/files/2600/2600-0.txt\"\n    book_text = urllib.request.urlopen(url).read().decode('utf-8')\n    assert word_count(book_text, \"hat\") == 33\n```\n\n\n\n```python\nCOLUMNS=60 pytest -v test_books.py\n```\n\n    \u001b[1m=================== test session starts ====================\u001b[0m\n    platform linux -- Python 3.8.12, pytest-6.2.5, py-1.10.0, pluggy-1.0.0 -- /usr/bin/python3.8\n    cachedir: .pytest_cache\n    rootdir: /home/matt/projects/courses/software_engineering_best_practices\n    plugins: anyio-3.3.4\n    collected 1 item                                           \u001b[0m\n    \n    test_books.py::test_word_counts \u001b[32mPASSED\u001b[0m\u001b[32m               [100%]\u001b[0m\n    \n    \u001b[32m==================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 1.93s\u001b[0m\u001b[32m =====================\u001b[0m\n\n\nThe test has passed and it took about two seconds. This is because it takes some time to download the file from the internet. For this example we *want* it to take some time as it helps demonstrate the point. In reality you will come across test data inputs which take some time (more than a few milliseconds) to create.\n\nThis creates a tension between wanting to have a large test suite which covers your code from lots of different angles and being able to run it very quickly and easily. An ideal test suite will run as quickly as possible as it will encourage you to run it more often. It's a good idea to have at least a subset of your tests which run through in some number of seconds rather than hours.\n\nTwo seconds is not bad for this test but if we want to test against multiple examples, it could get slow. Let's parametrise the test to add in a bunch more inputs:\n\n\n```python\n\nimport urllib.request\n\nimport pytest\n\nfrom books import word_count\n\n@pytest.mark.parametrize('word, count',  [\n    ('hat', 33),\n    ('freedom', 71),\n    ('electricity', 1),\n    ('testing', 3),\n    ('Prince', 1499),\n    ('internet', 0),\n    ('Russia', 71),\n    ('Pierre', 1260),\n    (None, 566334),\n])\ndef test_word_counts(word, count):\n    url = \"https://www.gutenberg.org/files/2600/2600-0.txt\"\n    book_text = urllib.request.urlopen(url).read().decode('utf-8')\n    assert word_count(book_text, word) == count\n```\n\n\n\n```python\nCOLUMNS=60 pytest -v test_books.py\n```\n\n    \u001b[1m=================== test session starts ====================\u001b[0m\n    platform linux -- Python 3.8.12, pytest-6.2.5, py-1.10.0, pluggy-1.0.0 -- /usr/bin/python3.8\n    cachedir: .pytest_cache\n    rootdir: /home/matt/projects/courses/software_engineering_best_practices\n    plugins: anyio-3.3.4\n    collected 9 items                                          \u001b[0m\n    \n    test_books.py::test_word_counts[hat-33] \u001b[32mPASSED\u001b[0m\u001b[32m       [ 11%]\u001b[0m\n    test_books.py::test_word_counts[freedom-71] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 22%]\u001b[0m\n    test_books.py::test_word_counts[electricity-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n    test_books.py::test_word_counts[testing-3] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 44%]\u001b[0m\n    test_books.py::test_word_counts[Prince-1499] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 55%]\u001b[0m\n    test_books.py::test_word_counts[internet-0] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 66%]\u001b[0m\n    test_books.py::test_word_counts[Russia-71] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 77%]\u001b[0m\n    test_books.py::test_word_counts[Pierre-1260] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 88%]\u001b[0m\n    test_books.py::test_word_counts[None-566334] \u001b[32mPASSED\u001b[0m\u001b[32m  [100%]\u001b[0m\n    \n    \u001b[32m==================== \u001b[32m\u001b[1m9 passed\u001b[0m\u001b[32m in 22.76s\u001b[0m\u001b[32m ====================\u001b[0m\n\n\nYou see here that it took about nine times as long. This is because the file is downloaded afresh for every test example where really, it only *needs* to be downloaded once.\n\nLet's move the slow setup into a fixture and give that as a parameter of the test function:\n\n\n```python\n\nimport urllib.request\n\nimport pytest\n\nfrom books import word_count\n\n@pytest.fixture()\ndef long_book():\n    url = \"https://www.gutenberg.org/files/2600/2600-0.txt\"\n    book_text = urllib.request.urlopen(url).read().decode('utf-8')\n    return book_text\n\n@pytest.mark.parametrize('word, count',  [\n    ('hat', 33),\n    ('freedom', 71),\n    ('electricity', 1),\n    ('testing', 3),\n    ('Prince', 1499),\n    ('internet', 0),\n    ('Russia', 71),\n    ('Pierre', 1260),\n    (None, 566334),\n])\ndef test_word_counts(long_book, word, count):\n    assert word_count(long_book, word) == count\n```\n\n\n\n\n```python\nCOLUMNS=60 pytest -v test_books.py\n```\n\n    \u001b[1m=================== test session starts ====================\u001b[0m\n    platform linux -- Python 3.8.12, pytest-6.2.5, py-1.10.0, pluggy-1.0.0 -- /usr/bin/python3.8\n    cachedir: .pytest_cache\n    rootdir: /home/matt/projects/courses/software_engineering_best_practices\n    plugins: anyio-3.3.4\n    collected 9 items                                          \u001b[0m\n    \n    test_books.py::test_word_counts[hat-33] \u001b[32mPASSED\u001b[0m\u001b[32m       [ 11%]\u001b[0m\n    test_books.py::test_word_counts[freedom-71] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 22%]\u001b[0m\n    test_books.py::test_word_counts[electricity-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n    test_books.py::test_word_counts[testing-3] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 44%]\u001b[0m\n    test_books.py::test_word_counts[Prince-1499] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 55%]\u001b[0m\n    test_books.py::test_word_counts[internet-0] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 66%]\u001b[0m\n    test_books.py::test_word_counts[Russia-71] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 77%]\u001b[0m\n    test_books.py::test_word_counts[Pierre-1260] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 88%]\u001b[0m\n    test_books.py::test_word_counts[None-566334] \u001b[32mPASSED\u001b[0m\u001b[32m  [100%]\u001b[0m\n    \n    \u001b[32m==================== \u001b[32m\u001b[1m9 passed\u001b[0m\u001b[32m in 27.78s\u001b[0m\u001b[32m ====================\u001b[0m\n\n\nPerhaps surprisingly, it is still taking very long time!\n\nBy default a fixture will run once for every test function that uses it. In our case we only need it to run once for all the tests in the test session so we can pass in the `scope` parameter to `pytest.fixture` and set it to `session`:\n\n\n```python\n\nimport urllib.request\n\nimport pytest\n\nfrom books import word_count\n\n@pytest.fixture(scope=\"session\")\ndef long_book():\n    url = \"https://www.gutenberg.org/files/2600/2600-0.txt\"\n    book_text = urllib.request.urlopen(url).read().decode('utf-8')\n    return book_text\n\n@pytest.mark.parametrize('word, count',  [\n    ('hat', 33),\n    ('freedom', 71),\n    ('electricity', 1),\n    ('testing', 3),\n    ('Prince', 1499),\n    ('internet', 0),\n    ('Russia', 71),\n    ('Pierre', 1260),\n    (None, 566334),\n])\ndef test_word_counts(long_book, word, count):\n    assert word_count(long_book, word) == count\n```\n\n\n\n```python\nCOLUMNS=60 pytest -v test_books.py\n```\n\n    \u001b[1m=================== test session starts ====================\u001b[0m\n    platform linux -- Python 3.8.12, pytest-6.2.5, py-1.10.0, pluggy-1.0.0 -- /usr/bin/python3.8\n    cachedir: .pytest_cache\n    rootdir: /home/matt/projects/courses/software_engineering_best_practices\n    plugins: anyio-3.3.4\n    collected 9 items                                          \u001b[0m\n    \n    test_books.py::test_word_counts[hat-33] \u001b[32mPASSED\u001b[0m\u001b[32m       [ 11%]\u001b[0m\n    test_books.py::test_word_counts[freedom-71] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 22%]\u001b[0m\n    test_books.py::test_word_counts[electricity-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n    test_books.py::test_word_counts[testing-3] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 44%]\u001b[0m\n    test_books.py::test_word_counts[Prince-1499] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 55%]\u001b[0m\n    test_books.py::test_word_counts[internet-0] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 66%]\u001b[0m\n    test_books.py::test_word_counts[Russia-71] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 77%]\u001b[0m\n    test_books.py::test_word_counts[Pierre-1260] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 88%]\u001b[0m\n    test_books.py::test_word_counts[None-566334] \u001b[32mPASSED\u001b[0m\u001b[32m  [100%]\u001b[0m\n    \n    \u001b[32m==================== \u001b[32m\u001b[1m9 passed\u001b[0m\u001b[32m in 3.39s\u001b[0m\u001b[32m =====================\u001b[0m\n\n\nNow it only takes about as long as a single test did since the slow part is only being done once.\n\n::: {#exampleN .callout-note icon=false title='Exercise'}\nAdd some more parameters to the test and check that it doesn't take any longer to run\n:::\n\n","srcMarkdownNoYaml":"\n\n\n\nAs we saw in the last section, when using parametrisation it's often useful to split your test function into two logical parts:\n\n- The data to be tested\n- The code to do the test\n\nThis is because we had a situation where we had one test function and multiple examples to test. The opposite situation also happens where we have multiple test functions, all of which want the same input data.\n\nThe name that pytest uses for \"data which are provided to test functions\" is *fixture* since it *fixes* a set of data against which to test.\n\nWe'll start with the example of the `add_arrays` function to explain the syntax but soon we'll need to use an example which demonstates the benefits more.\n\nTo make things clearer, we'll trim down the test file back to the basics. Just one test for `add_arrays`:\n\n\n```python\n\n\"\"\"\nThis module contains functions for manipulating and combining Python lists.\n\"\"\"\n\ndef add_arrays(x, y):\n    \"\"\"\n    This function adds together each element of the two passed lists.\n\n    Args:\n        x (list): The first list to add\n        y (list): The second list to add\n\n    Returns:\n        list: the pairwise sums of ``x`` and ``y``.\n\n    Examples:\n        >>> add_arrays([1, 4, 5], [4, 3, 5])\n        [5, 7, 10]\n    \"\"\"\n\n    if len(x) != len(y):\n        raise ValueError(\"Both arrays must have the same length.\")\n\n    z = []\n    for x_, y_ in zip(x, y):\n        z.append(x_ + y_)\n\n    return z\n```\n\n\n```python\n\nfrom arrays import add_arrays\n\ndef test_add_arrays():\n    a = [1, 2, 3]\n    b = [4, 5, 6]\n    expect = [5, 7, 9]\n    \n    output = add_arrays(a, b)\n    \n    assert output == expect\n```\n\nTo create our fixture we define a function which is decorated with the `pytest.fixture` decorator. Apart from that, all the function needs to do is return the data we want to provide to our tests, in this case, the two input lists:\n\n```python\nimport pytest\n\n@pytest.fixture\ndef pair_of_lists():\n    return [1, 2, 3], [4, 5, 6]\n```\n\n\nTo make the test functions make use of the fixture, we use the name of the fixture (`pair_of_lists`) as a parameter of the test function, similar to how we did with parametrisation:\n\n```python\ndef test_add_arrays(pair_of_lists):\n    ...\n```\n\nThe data are now available inside the function using that name and we can use it however we wish:\n\n```python\ndef test_add_arrays(pair_of_lists):\n    a, b = pair_of_lists\n    ...\n```\n\nThis isn't how functions and arguments usually work in Python. pytest is doing something magic here and is matching up the names of things which it knows are fixtures (due to the decorator) with the names of parameters to test functions, automatically running the fixture and passing in the data.\n\nNote that `pair_of_lists` here is not a test function. It does not contain any `assert`s and will not  explicitly appear in the `pytest` output.\n\nPutting it all together, we end up with:\n\n\n```python\n\nimport pytest\n\nfrom arrays import add_arrays\n\n@pytest.fixture\ndef pair_of_lists():\n    return [1, 2, 3], [4, 5, 6]\n\ndef test_add_arrays(pair_of_lists):\n    a, b = pair_of_lists\n    expect = [5, 7, 9]\n    \n    output = add_arrays(a, b)\n    \n    assert output == expect\n```\n\nWhen we run the test suite, pytest will automatically run the `pair_of_lists` function for any test that has it as an input and pass in the result.\n\n\n```python\nCOLUMNS=60 pytest -v test_arrays.py\n```\n\n    \u001b[1m=================== test session starts ====================\u001b[0m\n    platform linux -- Python 3.8.12, pytest-6.2.5, py-1.10.0, pluggy-1.0.0 -- /usr/bin/python3.8\n    cachedir: .pytest_cache\n    rootdir: /home/matt/projects/courses/software_engineering_best_practices\n    plugins: anyio-3.3.4\n    collected 1 item                                           \u001b[0m\n    \n    test_arrays.py::test_add_arrays \u001b[32mPASSED\u001b[0m\u001b[32m               [100%]\u001b[0m\n    \n    \u001b[32m==================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m =====================\u001b[0m\n\n\n## A different example\n\nIt might be hard to see the benefit of fixtures with this rather contrived example in which there aren't repeated uses of the same input data. So lets take a look at a more sensible one where using a fixture makes sense.\n\nMake a new file called `books.py` which contains the following:\n\n\n```python\n\ndef word_count(text, word=''):\n    \"\"\"\n    Count the number of occurences of ``word`` in a string.\n    If ``word`` is not set, count all words.\n    \n    Args:\n        text (str): the text corpus to search through\n        word (str): the word to count instances of\n\n    Returns:\n        int: the count of ``word`` in ``text``\n    \"\"\"\n    if word:\n        count = 0\n        for text_word in text.split():\n            if text_word == word:\n                count += 1\n        return count\n    else:\n        return len(text.split())\n```\n\n\n\nTo test this function we want a corpus of text to test it on. For the purposes of this example and to simulate a complex data input, we will download the contents of a particularly long novel from Project Gutenberg. Our test function uses [`urllib.request`](https://docs.python.org/3/library/urllib.request.html) to download the text, converts it to a string and passes that to the `word_count` function.\n\nAt first we will simply check that the word \"hat\" appears 33 times in the book:\n\n\n```python\n\nimport urllib.request\n\nfrom books import word_count\n\ndef test_word_counts():\n    url = \"https://www.gutenberg.org/files/2600/2600-0.txt\"\n    book_text = urllib.request.urlopen(url).read().decode('utf-8')\n    assert word_count(book_text, \"hat\") == 33\n```\n\n\n\n```python\nCOLUMNS=60 pytest -v test_books.py\n```\n\n    \u001b[1m=================== test session starts ====================\u001b[0m\n    platform linux -- Python 3.8.12, pytest-6.2.5, py-1.10.0, pluggy-1.0.0 -- /usr/bin/python3.8\n    cachedir: .pytest_cache\n    rootdir: /home/matt/projects/courses/software_engineering_best_practices\n    plugins: anyio-3.3.4\n    collected 1 item                                           \u001b[0m\n    \n    test_books.py::test_word_counts \u001b[32mPASSED\u001b[0m\u001b[32m               [100%]\u001b[0m\n    \n    \u001b[32m==================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 1.93s\u001b[0m\u001b[32m =====================\u001b[0m\n\n\nThe test has passed and it took about two seconds. This is because it takes some time to download the file from the internet. For this example we *want* it to take some time as it helps demonstrate the point. In reality you will come across test data inputs which take some time (more than a few milliseconds) to create.\n\nThis creates a tension between wanting to have a large test suite which covers your code from lots of different angles and being able to run it very quickly and easily. An ideal test suite will run as quickly as possible as it will encourage you to run it more often. It's a good idea to have at least a subset of your tests which run through in some number of seconds rather than hours.\n\nTwo seconds is not bad for this test but if we want to test against multiple examples, it could get slow. Let's parametrise the test to add in a bunch more inputs:\n\n\n```python\n\nimport urllib.request\n\nimport pytest\n\nfrom books import word_count\n\n@pytest.mark.parametrize('word, count',  [\n    ('hat', 33),\n    ('freedom', 71),\n    ('electricity', 1),\n    ('testing', 3),\n    ('Prince', 1499),\n    ('internet', 0),\n    ('Russia', 71),\n    ('Pierre', 1260),\n    (None, 566334),\n])\ndef test_word_counts(word, count):\n    url = \"https://www.gutenberg.org/files/2600/2600-0.txt\"\n    book_text = urllib.request.urlopen(url).read().decode('utf-8')\n    assert word_count(book_text, word) == count\n```\n\n\n\n```python\nCOLUMNS=60 pytest -v test_books.py\n```\n\n    \u001b[1m=================== test session starts ====================\u001b[0m\n    platform linux -- Python 3.8.12, pytest-6.2.5, py-1.10.0, pluggy-1.0.0 -- /usr/bin/python3.8\n    cachedir: .pytest_cache\n    rootdir: /home/matt/projects/courses/software_engineering_best_practices\n    plugins: anyio-3.3.4\n    collected 9 items                                          \u001b[0m\n    \n    test_books.py::test_word_counts[hat-33] \u001b[32mPASSED\u001b[0m\u001b[32m       [ 11%]\u001b[0m\n    test_books.py::test_word_counts[freedom-71] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 22%]\u001b[0m\n    test_books.py::test_word_counts[electricity-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n    test_books.py::test_word_counts[testing-3] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 44%]\u001b[0m\n    test_books.py::test_word_counts[Prince-1499] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 55%]\u001b[0m\n    test_books.py::test_word_counts[internet-0] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 66%]\u001b[0m\n    test_books.py::test_word_counts[Russia-71] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 77%]\u001b[0m\n    test_books.py::test_word_counts[Pierre-1260] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 88%]\u001b[0m\n    test_books.py::test_word_counts[None-566334] \u001b[32mPASSED\u001b[0m\u001b[32m  [100%]\u001b[0m\n    \n    \u001b[32m==================== \u001b[32m\u001b[1m9 passed\u001b[0m\u001b[32m in 22.76s\u001b[0m\u001b[32m ====================\u001b[0m\n\n\nYou see here that it took about nine times as long. This is because the file is downloaded afresh for every test example where really, it only *needs* to be downloaded once.\n\nLet's move the slow setup into a fixture and give that as a parameter of the test function:\n\n\n```python\n\nimport urllib.request\n\nimport pytest\n\nfrom books import word_count\n\n@pytest.fixture()\ndef long_book():\n    url = \"https://www.gutenberg.org/files/2600/2600-0.txt\"\n    book_text = urllib.request.urlopen(url).read().decode('utf-8')\n    return book_text\n\n@pytest.mark.parametrize('word, count',  [\n    ('hat', 33),\n    ('freedom', 71),\n    ('electricity', 1),\n    ('testing', 3),\n    ('Prince', 1499),\n    ('internet', 0),\n    ('Russia', 71),\n    ('Pierre', 1260),\n    (None, 566334),\n])\ndef test_word_counts(long_book, word, count):\n    assert word_count(long_book, word) == count\n```\n\n\n\n\n```python\nCOLUMNS=60 pytest -v test_books.py\n```\n\n    \u001b[1m=================== test session starts ====================\u001b[0m\n    platform linux -- Python 3.8.12, pytest-6.2.5, py-1.10.0, pluggy-1.0.0 -- /usr/bin/python3.8\n    cachedir: .pytest_cache\n    rootdir: /home/matt/projects/courses/software_engineering_best_practices\n    plugins: anyio-3.3.4\n    collected 9 items                                          \u001b[0m\n    \n    test_books.py::test_word_counts[hat-33] \u001b[32mPASSED\u001b[0m\u001b[32m       [ 11%]\u001b[0m\n    test_books.py::test_word_counts[freedom-71] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 22%]\u001b[0m\n    test_books.py::test_word_counts[electricity-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n    test_books.py::test_word_counts[testing-3] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 44%]\u001b[0m\n    test_books.py::test_word_counts[Prince-1499] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 55%]\u001b[0m\n    test_books.py::test_word_counts[internet-0] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 66%]\u001b[0m\n    test_books.py::test_word_counts[Russia-71] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 77%]\u001b[0m\n    test_books.py::test_word_counts[Pierre-1260] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 88%]\u001b[0m\n    test_books.py::test_word_counts[None-566334] \u001b[32mPASSED\u001b[0m\u001b[32m  [100%]\u001b[0m\n    \n    \u001b[32m==================== \u001b[32m\u001b[1m9 passed\u001b[0m\u001b[32m in 27.78s\u001b[0m\u001b[32m ====================\u001b[0m\n\n\nPerhaps surprisingly, it is still taking very long time!\n\nBy default a fixture will run once for every test function that uses it. In our case we only need it to run once for all the tests in the test session so we can pass in the `scope` parameter to `pytest.fixture` and set it to `session`:\n\n\n```python\n\nimport urllib.request\n\nimport pytest\n\nfrom books import word_count\n\n@pytest.fixture(scope=\"session\")\ndef long_book():\n    url = \"https://www.gutenberg.org/files/2600/2600-0.txt\"\n    book_text = urllib.request.urlopen(url).read().decode('utf-8')\n    return book_text\n\n@pytest.mark.parametrize('word, count',  [\n    ('hat', 33),\n    ('freedom', 71),\n    ('electricity', 1),\n    ('testing', 3),\n    ('Prince', 1499),\n    ('internet', 0),\n    ('Russia', 71),\n    ('Pierre', 1260),\n    (None, 566334),\n])\ndef test_word_counts(long_book, word, count):\n    assert word_count(long_book, word) == count\n```\n\n\n\n```python\nCOLUMNS=60 pytest -v test_books.py\n```\n\n    \u001b[1m=================== test session starts ====================\u001b[0m\n    platform linux -- Python 3.8.12, pytest-6.2.5, py-1.10.0, pluggy-1.0.0 -- /usr/bin/python3.8\n    cachedir: .pytest_cache\n    rootdir: /home/matt/projects/courses/software_engineering_best_practices\n    plugins: anyio-3.3.4\n    collected 9 items                                          \u001b[0m\n    \n    test_books.py::test_word_counts[hat-33] \u001b[32mPASSED\u001b[0m\u001b[32m       [ 11%]\u001b[0m\n    test_books.py::test_word_counts[freedom-71] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 22%]\u001b[0m\n    test_books.py::test_word_counts[electricity-1] \u001b[32mPASSED\u001b[0m\u001b[32m [ 33%]\u001b[0m\n    test_books.py::test_word_counts[testing-3] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 44%]\u001b[0m\n    test_books.py::test_word_counts[Prince-1499] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 55%]\u001b[0m\n    test_books.py::test_word_counts[internet-0] \u001b[32mPASSED\u001b[0m\u001b[32m   [ 66%]\u001b[0m\n    test_books.py::test_word_counts[Russia-71] \u001b[32mPASSED\u001b[0m\u001b[32m    [ 77%]\u001b[0m\n    test_books.py::test_word_counts[Pierre-1260] \u001b[32mPASSED\u001b[0m\u001b[32m  [ 88%]\u001b[0m\n    test_books.py::test_word_counts[None-566334] \u001b[32mPASSED\u001b[0m\u001b[32m  [100%]\u001b[0m\n    \n    \u001b[32m==================== \u001b[32m\u001b[1m9 passed\u001b[0m\u001b[32m in 3.39s\u001b[0m\u001b[32m =====================\u001b[0m\n\n\nNow it only takes about as long as a single test did since the slow part is only being done once.\n\n::: {#exampleN .callout-note icon=false title='Exercise'}\nAdd some more parameters to the test and check that it doesn't take any longer to run\n:::\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":true,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"shift-heading-level-by":1,"highlight-style":"github","output-file":"040-testing-data.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.57","theme":["cosmo","../styles.scss"],"title":"Input data for tests"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}